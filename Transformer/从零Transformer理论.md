# 从零Tramsformer理论

## 预训练

### 用处？

很多项目没有大数据支持？猫狗分类任务，只有100张猫和狗的图片

已知100000张鹅和鸭的图片->有人做过这样的模型->固定浅层参数，随机初始化深层参数，用少量数据训练深层参数

**越浅的层学到的特征越通用（横竖撇捺），越深的层学到的特征和具体任务的关联性越强（人脸-人脸轮廓、汽车-汽车轮廓）**

浅层：靠近输入；深层：靠近输出



冻结：浅层参数不变

微调：浅层参数会跟着任务B训练而改变



### 是什么?

通过一个已经训练好的模型A，去完成一个小数据量的任务B

任务A和任务B极其相似



### 怎么用？

`fairseq`、`transformer`库



### 总结

对于一个具有少量数据的任务 A，首先通过一个现有的大量数据搭建一个 CNN 模型 A，由于 CNN的浅层学到的特征通用性特别强，因此在搭建一个 CNN 模型 B，其中模型 B 的浅层参数使用模型 A 的浅层参数，模型 B 的高层参数随机初始化，然后通过冻结或微调的方式利用任务 A 的数据训练模型 B，模型 B 就是对应任务 A 的模型



## 4 统计语言模型

### 语言模型

语言（人说的话）+模型（表示某个东西，完成某个任务）



### 统计语言模型

基本思想：**计算条件概率**

$P(w_1,w_2,⋯,w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)⋯p(w_n|w_1,w_2,⋯,w_{n−1})=∏_iP(w_i|w_1,w_2,⋯,w_{i−1})$



两个任务：

1. 比较。假设给定两句话 **“判断这个词的磁性”** 和 **“判断这个词的词性”**，语言模型会认为后者更自然。转化成数学语言也就是：

`P(判断，这个，词，的，词性)>P(判断，这个，词，的，磁性)`

2. 预测。假设给定一句话做填空 **“判断这个词的\_\_\__\____”**，则问题就变成了给定前面的词，找出后面的一个词是什么，转化成数学语言就是：

`P(词性|判断，这个，词，的)>P(磁性|判断，这个，词，的)`

（遍历词典库V中每一个词计算）



### n元统计语言模型

对一句话的前面很多个词，只取最接近最后面的n个

二元统计语言模型：

$ P(词性|的) $





### 平滑策略

对于绝大多数具有现实意义的文本，会出现数据稀疏的情况，例如**训练时未出现，测试时出现了的未登录单词**

$ P(w_i|w_{i−1})= \frac{count(w_{i−1},w_i)+1}{count(w_{i−1})+|V|} $



## 5 神经网络语言模型 NNLM->为了预测下一个词

用神经网络的方法解决语言问题



### 独热编码

假设词典V共有8个单词，给出一个8*8的矩阵

"time": [1,0,0,0,0,0,0,0]

"fruit": [0,1,0,0,0,0,0,0]

关联性：余弦相似度来计算。在这里是两个向量点乘，显然只有两个单词相同时结果才不为0，因此并没有解决词之间关联性的问题。

缺点：维度灾难，表示不了相似性





### 词向量（神经网络语言模型的副产品）

假设词的独热编码为$W_i$(1×V)，训练模型时会计算$W_i·Q$；$Q$为可学习的参数，大小为V×m。

那么$C_i = W_i · Q$ 为词向量

这样$C_i$的大小就可以通过控制$Q$的维度来控制，比独热编码更方便存储和计算；同时一定程度上解决了词之间相似度的问题。



### 总结

神经网络语言模型：通过神经网络解决两个人说的话的问题

有一个副产品-Q矩阵，得到词向量，可以控制词向量大小，方便计算，解决相似度问题



## 6 Word2Vec模型->为了得到词向量

目的：得到词向量，而不是仅仅将词向量作为副产物

不考虑细节，word2vec和NNLM结构上一样

![](./assets/word2vec.jpg)

### CBOW

给出一个词的上下文，得到这个词

"我是最 _ 的Nick"



### Skip-gram

给出一个词，得到这个词的上下文

"帅"

"我是最_的Nick"

### NNLM和Word2Vec的区别

NNLM -> 重点是预测下一个词

Word2Vec -> 重点是得到Q矩阵



### Word2Vec的缺点

Q矩阵的设计

一词多义没法解决："apple"经过Q矩阵计算的词向量只可能是一个值



## 7 预训练语言模型的下游任务改造简介

先用独热编码，再通过Word2Vec预训练好的Q矩阵直接得到词向量，然后进行接下来的任务



## 补充：RNN

RNN实际上就是一个带有**记忆**的时间序列的预测模型，每个神经元包含了当前信息和之前的信息



<img src=".\assets\RNN-unrolled.png" style="zoom:150%;" />

上图左边部分称作 RNN 的一个 timestep，在这个 timestep 中可以看到，在 t 时刻，输入变量 xt，通过 RNN 的一个基础模块 A，输出变量 ht，而 t 时刻的信息，将会传递到下一个时刻 t+1

每次基于当前的观测$ X_i $以及之前的隐藏层信息$h_{i-1}$获得输出$o_i$（即图上的$h_i$）和传递给下一个神经元的隐藏层信息$h_i$（图上未画）





### RNN的问题

梯度消失/爆炸，无法长期保持比较早期的记忆

还是没解决一词多义问题



## 补充：LSTM





## 8 ELMo模型（双向LSTM模型解决词向量多义问题）





## 9 Attention 注意力机制

大数据：什么数据都有，有重要的也有不重要的

传统神经网络如CNN、LSTM无法确定哪个重要

注意力机制解决哪些数据比较重要的问题

我们会把我们的焦点聚焦在比较重要的事物上



### 怎么做注意力

Q: Query，可以视为当前任务或上下文中的“焦点”或“问题”

K: Key，是与输入数据中的每个元素相关联的表示，它们与Q进行比较，以确定每个输入元素与当前查询的相关性。

V: Value, 是输入数据中每个元素的表示，包含了实际的信息内容。在注意力机制中，V根据与Q的相关性（通过K计算出的权重）进行加权求和，从而生成最终的注意力输出。



首先Q和K求点积，得到Query和K对应的分量$k_i$的关联度。值大的关联度大，再经过类softmax函数将这些值转化为概率分布。

![](.\assets\Attention.png)

再将这个获得的概率分布作用于V的所有分量，得到最终的注意力值





### `K`和`V`矩阵的关系：（便于理解，来自chatglm）

- **`K`矩阵用于计算注意力得分**：`K`矩阵中的每个键向量与查询矩阵`Q`中的每个查询向量进行比较，以确定输入序列中不同元素之间的相关性或重要性。
- **`V`矩阵提供输出的“值”**：一旦计算出了注意力权重，这些权重就用来对`V`矩阵中的值进行加权。这意味着，对于每个查询位置，`V`矩阵中的值将根据与该查询最相关的键来加权，从而形成该位置的输出表示。
- **关系**：`K`和`V`矩阵是成对出现的。在计算注意力时，`K`决定了对`V`中每个值的权重分配。如果某个键`K_i`与某个查询`Q_j`非常相关，则对应的值`V_i`在输出表示中将具有更高的权重。

## 10 自注意力机制

1. 首先对输入并做过embedding的每个词向量X，分别乘以$W_Q$、$W_K$、$W_V$矩阵得到Q、K、V向量，代表这个单词的Query、Key、Value

![](./assets/QKV.jpg)



2. 对每个词$i$，遍历所有词$j$，计算$Q_i·K_j$，得到词$i$和词$j$的“相似度”；再做一个scale函数，防止`softmax`过程中出现极端情况
3. 对上述的词$i$和每一个词$j$相乘做的向量做`softmax`，得到$i$和每一个$j$相似度的概率形式
4. 将上述概率与每一个单词的$V$矩阵相乘，并求和，得到词$i$的最终注意力值

![](./assets/attention.jpg)

## 10+ 自注意力机制和注意力机制的区别

自注意力机制Q、K、V同源，均来自输入的词向量X

注意力机制K、V同源，Q是额外的查询输入



## 11 Self-Attention相较于RNN和LSTM的优缺点

RNN：对比较靠前的数据记忆力很弱，无法做长序列，当一句话达到50个字，效果很差了

LSTM通过各种门，选择性的可以记忆之前的信息（200个词）



### Self-Attention和RNNs的区别

RNNs 长序列依赖问题

无法做并行



Self-Attention可以做并行（每个单词$i$的输出注意力值都可以同步运算）



但Self-Attention随输入序列长度计算耗时增大更快（复杂度O(n^2)）

而RNNs这种序列模型只需要从头到尾计算一次，O(n)



## 12 Masked Self-Attention 掩码自注意力机制

在自注意力机制上加了改进

为什么要做这个改进：生成模型，生成单词，一个一个生成的

当我们做生成任务的时候，我们也想对生成的这个单词做注意力计算，但是，生成的句子是一个单词一个单词生成的



训练时，当要计算的Query枚举到$i$时，不能看到$i$之后的key

![](./assets/mask_1.jpg)

应用掩码后得到的`softmax`后得出的概率可能如下：

![](./assets/mask_2.jpg)



## 13 Multi-Head Self-Attention
