{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25 VGG - 使用块的网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相较于LeNet（引入卷积），AlexNet（在LeNet上增加层数+一些优化），VGG引入块的概念，对前两者进行了封装。将一些卷积层+池化层的组合打包成一个块，然后将多个块打包成一个网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深 vs 宽？\n",
    "\n",
    "使用 5 * 5 卷积核，单层的参数量会变大，总参数量相同时层数较浅。\n",
    "\n",
    "使用 3 * 3 卷积核，单层的参数量会变小，总参数量相同时层数较深。\n",
    "\n",
    "最终发现深但窄效果更好\n",
    "\n",
    "## VGG 块\n",
    "\n",
    "使用 3 * 3 卷积核（padding=1以保证每次卷积后图像大小不变）和 2 * 2 最大池化层（stride=2）\n",
    "\n",
    "## VGG 架构\n",
    "\n",
    "使用多个VGG块，最后接全连接层。\n",
    "\n",
    "不同次数的重复块得到不同的架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet vs AlexNet vs VGG\n",
    "\n",
    "+ LeNet\n",
    "\n",
    "2 卷积 + 池化\n",
    "\n",
    "2 全连接层\n",
    "\n",
    "+ AlexNet\n",
    "\n",
    "更大更深\n",
    "\n",
    "ReLU, Dropout, 数据增强\n",
    "\n",
    "+ VGG\n",
    "\n",
    "重复的VGG块，更大更深的AlexNet"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
